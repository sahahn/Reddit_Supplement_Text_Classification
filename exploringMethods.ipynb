{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sage Hahn\n",
    "\n",
    "Data Science Final Project\n",
    "\n",
    "'Exploring a range of different methods', In this file I complete the bulk on my exploratory data analysis in answering my research question.\n",
    "\n",
    "\n",
    "For my approach, it is important to try it on already established problems. The first is a very common one in text processing, using the twenty news groups datatset, imported from sklearn. I will first establish a baseline accuracy by just going through and implimenting a binary test classifier on this dataset.\n",
    "\n",
    "This baseline example is adpted from http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define all of the functions I will be using throughout, defined in the order they are used\n",
    "\n",
    "def create_test_labels(class_num, test_target):\n",
    "    '''This function creates the test labels given a valid class between 0-19 for the\n",
    "    Twenty news dataset, and returns them as an array'''\n",
    "    y_test = []\n",
    "    \n",
    "    for test_entry in test_target:\n",
    "        if (test_entry == class_num):\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)\n",
    "            \n",
    "    return y_test\n",
    "\n",
    "def create_train_set(class_num, ratio, train_data, train_target):\n",
    "    '''This function creates the training set data and labels, \n",
    "       and needs to bw given the train and test data'''\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    data = zip(train_data, train_target)\n",
    "\n",
    "    #First add just all instances of the class\n",
    "    for entry, label in data:\n",
    "        if (label == class_num):\n",
    "            X_train.append(entry)\n",
    "            y_train.append(1)\n",
    "\n",
    "    #Now add the rest of the classes according to the ratio\n",
    "    amount = len(X_train) * ratio\n",
    "    count = 0\n",
    "\n",
    "    data = zip(train_data, train_target)\n",
    "\n",
    "    #Next we will randomly add from the remaining test data by adding the correct ratio of not class X\n",
    "    for entry, label in data:\n",
    "        if count < amount:\n",
    "            if (label != class_num):\n",
    "                X_train.append(entry)\n",
    "                y_train.append(0)\n",
    "\n",
    "                count += 1\n",
    "                \n",
    "    return X_train, y_train\n",
    "\n",
    "def get_metrics(text_clf, X_train, X_test, y_train, y_test):\n",
    "    '''This function returns various metrics, and assumes global variable twenty_test.data.\n",
    "       Returns the f1 score, which is a measure of precision and recall'''\n",
    "    \n",
    "    #Now fit and classify\n",
    "    text_clf.fit(X_train, y_train)\n",
    "    predicted = text_clf.predict(X_test)\n",
    "    \n",
    "    f1 = metrics.f1_score(y_test, predicted)\n",
    "    precision = metrics.precision_score(y_test, predicted)\n",
    "    recall = metrics.recall_score(y_test, predicted)\n",
    "    \n",
    "    return f1, precision, recall\n",
    "\n",
    "def get_average_f1_ratios(text_clf):\n",
    "    '''This function recieves a classifer as an input, and iterates over all\n",
    "       possible different classes, getting the average f1, precision and recall scores over\n",
    "       the different possible ratios of training data. It returns the averages, as three arrays.'''\n",
    "    \n",
    "    #Init the ratios list w/ a 0 at first, to make the ratios index align with the ratio\n",
    "    f1_ratios = [0]\n",
    "    precision_ratios = [0]\n",
    "    recall_ratios = [0]\n",
    "    \n",
    "    #Run for ratios 1-10\n",
    "    for ratio in range(1,11):\n",
    "        \n",
    "        #Take the average F1 score for each class\n",
    "        f1_total = 0\n",
    "        precision_total = 0\n",
    "        recall_total = 0\n",
    "        \n",
    "        #For each class,\n",
    "        for cl in range(20):\n",
    "            y_test = create_test_labels(cl, twenty_test.target)\n",
    "            X_train, y_train = create_train_set(cl, ratio, twenty_train.data, twenty_train.target)\n",
    "            \n",
    "            #Get the metrics\n",
    "            f1, precision, recall = get_metrics(text_clf, X_train, twenty_test.data, y_train, y_test)\n",
    "    \n",
    "            #Compute the total\n",
    "            f1_total += f1\n",
    "            precision_total += precision\n",
    "            recall_total += recall\n",
    "        \n",
    "        #Compute the average, and add to the respective array\n",
    "        f1_ratios.append(f1_total / 20)\n",
    "        precision_ratios.append(precision_total / 20)\n",
    "        recall_ratios.append(recall_total / 20)\n",
    "        \n",
    "        print(\"At step: \", ratio)\n",
    "        \n",
    "    return f1_ratios, precision_ratios, recall_ratios\n",
    "\n",
    "def preproc(source):\n",
    "    '''preproc is used to preprocess the twenty newsgroup data to\n",
    "       conform with the rest of the data used'''\n",
    "    \n",
    "    #The output array\n",
    "    dest = []\n",
    "    \n",
    "    for entry in source:\n",
    "\n",
    "        words = nltk.word_tokenize(entry.lower()) #Convert to lowercase\n",
    "\n",
    "        ent = \"\"\n",
    "\n",
    "        #Stem each word, and re add to entry\n",
    "        for word in words:\n",
    "            word = stemmer.stem(word)\n",
    "\n",
    "            ent = ent + \" \" + word\n",
    "\n",
    "        dest.append(ent)\n",
    "        \n",
    "    return dest\n",
    "\n",
    "def createCorpus(read_paths):\n",
    "    '''Create a corpus, takes in a series of read paths, joins them together,\n",
    "       and returns the results as a corpus of text documents '''\n",
    "    \n",
    "    corpus = []\n",
    "    posts = []\n",
    "    \n",
    "    #For each file to load, load the pkl array, and add it to corpus\n",
    "    for path in read_paths:\n",
    "        with open(path, 'rb') as fp:\n",
    "            posts = pickle.load(fp)\n",
    "\n",
    "        #add that file to the corpus\n",
    "        corpus = corpus + posts\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "def createQuickTrainingData(subject_keys, ratio):\n",
    "    '''Creates a quick classifier from key words, though it assumes corpus is defined,\n",
    "       and returns X,y where X is the training data and y are the labels. As input it takes\n",
    "       subject keywords, and a training ratio- this is used a helper function to quickly test a method\n",
    "       of augmenting data'''\n",
    "\n",
    "    #Store instances here\n",
    "    lines_with_key = []\n",
    "    \n",
    "    #For each line in the corpus, only add if not already present\n",
    "    for line in corpus:\n",
    "\n",
    "        found = False\n",
    "        for key in subject_keys:\n",
    "            if (key in line) and (not found):\n",
    "                lines_with_key.append(line)\n",
    "                found = True\n",
    "\n",
    "    y = []\n",
    "\n",
    "    for line in lines_with_key:\n",
    "        y.append(1)\n",
    "\n",
    "    #Add a random number of items based on the ratio given\n",
    "    rand_items = random.sample(corpus, (len(lines_with_key)*ratio))\n",
    "    \n",
    "    X = lines_with_key + rand_items\n",
    "\n",
    "    #If not the desired class, label as 0\n",
    "    for line in lines_with_key:\n",
    "        for num in range(ratio):\n",
    "            y.append(0)\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "def GridSearch(loss_functions, n_grams, max_features_options, ratio_range, word_keys):\n",
    "    '''My version of GridSearch returning f1 score, precision and recall,\n",
    "       given different loss_functions, n_gram settings, options for max_features, and ratios'''\n",
    "    \n",
    "    #I will store the results in a weird way, results will hold a 2d lists, 1d with the scores, 1d with the label info\n",
    "    results = []\n",
    "\n",
    "    #For updates on progress\n",
    "    r = 0\n",
    "    final_r = ((ratio_range[1]-ratio_range[0]) * len(loss_functions) * len(n_grams) * len(max_features_options))\n",
    "\n",
    "    #2-7 should be enough\n",
    "    for ratio in range(ratio_range[0],ratio_range[1]):\n",
    "        \n",
    "        X, y = createQuickTrainingData(word_keys, ratio)\n",
    "\n",
    "        #For each different classifier option\n",
    "        for loss_f in loss_functions:\n",
    "            for gram in n_grams:\n",
    "                for feat in max_features_options:\n",
    "                    \n",
    "                    #Define the clasifier based on the different parameters\n",
    "                    text_clf = Pipeline([('vect', CountVectorizer(ngram_range=gram, max_features=feat)),('tfidf', TfidfTransformer()),\n",
    "                             ('clf', SGDClassifier(loss=loss_f, penalty='l2', alpha=1e-3,\n",
    "                               random_state=22, max_iter=5))])\n",
    "\n",
    "                    label = [ratio, loss_f, gram, feat]\n",
    "\n",
    "                    #Add to the weird 2d list the score + label\n",
    "                    results.append([get_metrics(text_clf, X, X_test, y, y_test), label])\n",
    "\n",
    "                    r += 1\n",
    "\n",
    "                    #Print progress updates\n",
    "                    if (r % 25 == 0):\n",
    "                        print(r, \"/\", final_r)\n",
    "                        \n",
    "    return results\n",
    "\n",
    "def printF1(results):\n",
    "    '''Sorts the results by f1 score, and print out the top 10, and bottom 5,\n",
    "       lastly, return the bestF1 score'''\n",
    "    \n",
    "    sorted_results = sorted(results,key=lambda x: (x[0][0]), reverse=True)\n",
    "\n",
    "    bestF1 = sorted_results[0][0][0]\n",
    "    \n",
    "    print(\"Top 10\")\n",
    "    for line in sorted_results[:10]:\n",
    "        print(\"f1 score: \", line[0][0], \"for\", line[1])\n",
    "\n",
    "    print(\"Bottom 5\")\n",
    "    for line in sorted_results[-5:]:\n",
    "        print(\"f1 score: \", line[0][0], \"for\", line[1])\n",
    "        \n",
    "        \n",
    "    return bestF1\n",
    "\n",
    "def get_N_Gram_Count(sentence_list, n):\n",
    "    '''Given a list of sentences, and an int n, returns a Counter, with \n",
    "       counts for the all possible n-gram's in the sentence_list '''\n",
    "    \n",
    "    #Define the counter\n",
    "    cnt = collections.Counter()\n",
    "    \n",
    "    \n",
    "    for line in sentence_list:\n",
    "        words = nltk.word_tokenize(line)\n",
    "    \n",
    "        for i in range(len(words) - n):\n",
    "            \n",
    "            word = \"\"\n",
    "\n",
    "            #Create the n gram\n",
    "            for c in range(n):\n",
    "                word = word + \" \" + words[i+c]\n",
    "\n",
    "            #Add the count\n",
    "            cnt[word] += 1\n",
    "\n",
    "    #return the counter\n",
    "    return cnt\n",
    "\n",
    "def ModifiedGridSearch(loss_functions, n_grams, max_features_options, ratio_range, class_num, class_keys):\n",
    "    '''modfied version of GridSearch from above, returning f1 score, precision and recall,\n",
    "       given different loss_functions, n_gram settings, options for max_features, and ratios.'''\n",
    "    #I will store the results in a weird way, results will hold a 2d lists, 1d with the scores, 1d with the label info\n",
    "    results = []\n",
    "\n",
    "    #For updates on progress\n",
    "    r = 0\n",
    "    final_r = ((ratio_range[1]-ratio_range[0]) * len(loss_functions) * len(n_grams) * len(max_features_options))\n",
    "    \n",
    "    #Create y_test\n",
    "    y_test = create_test_labels(class_num, twenty_test.target)\n",
    "\n",
    "    for ratio in range(ratio_range[0],ratio_range[1]):\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        #Get the X and y train based on the ratio\n",
    "        X_train, y_train = create_train_set(class_num, ratio, twenty_train_data_proc, twenty_train.target)\n",
    "        \n",
    "        X, y = createQuickTrainingData(class_keys, ratio)\n",
    "        X = X + X_train\n",
    "        y = y + y_train\n",
    "\n",
    "        #For each different classifier option\n",
    "        for loss_f in loss_functions:\n",
    "            for gram in n_grams:\n",
    "                for feat in max_features_options:\n",
    "\n",
    "                    text_clf = Pipeline([('vect', CountVectorizer(ngram_range=gram, max_features=feat)),('tfidf', TfidfTransformer()),\n",
    "                             ('clf', SGDClassifier(loss=loss_f, penalty='l2', alpha=1e-3,\n",
    "                               random_state=22, max_iter=5))])\n",
    "\n",
    "\n",
    "                    label = [ratio, loss_f, gram, feat]\n",
    "\n",
    "                    #Add to the weird 2d list the score + label\n",
    "                    results.append([get_metrics(text_clf, X, X_test, y, y_test), label])\n",
    "\n",
    "                    r += 1\n",
    "\n",
    "                    #Print progress updates\n",
    "                    if (r % 25 == 0):\n",
    "                        print(r, \"/\", final_r)\n",
    "                        \n",
    "    return results\n",
    "\n",
    "\n",
    "def getKeyWords(class_num, ratio):\n",
    "    '''Given a class number and a ratio, print out the most common 1,2 n grams,\n",
    "       this is used as a helper function in helping a user generate key words'''\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    #Redfine X_train and y_test\n",
    "    y_test = create_test_labels(class_num, twenty_test.target)\n",
    "    X_train, y_train = create_train_set(class_num, ratio, twenty_train_data_proc, twenty_train.target)\n",
    "    \n",
    "    train_data = zip (X_train, y_train)\n",
    "\n",
    "    #Init class_x and and not_class_x arrays\n",
    "    class_X = []\n",
    "    not_class_X = []\n",
    "\n",
    "    for line,label in train_data:\n",
    "        if (label == 1):\n",
    "            class_X.append(line)\n",
    "        else:\n",
    "            not_class_X.append(line)\n",
    "    \n",
    "    #Print out which class this is for\n",
    "    print(twenty_train.target_names[class_num])\n",
    "    \n",
    "    #For 1,2 grams print out the most common, that are the least common in not class x\n",
    "    for i in range(1,3):\n",
    "        cnt_class_X = get_N_Gram_Count(class_X, i)\n",
    "        cnt_not_class_X = get_N_Gram_Count(not_class_X, i)\n",
    "\n",
    "        cnt_class_X.subtract(cnt_not_class_X)\n",
    "\n",
    "        print(\"N gram =\", i)\n",
    "        print(cnt_class_X.most_common(10))\n",
    "\n",
    "def printPR(results):\n",
    "    '''Sorts the results by preicison instead, and print out the top 10'''\n",
    "    sorted_results = sorted(results,key=lambda x: (x[0][1]), reverse=True)\n",
    "\n",
    "    print(\"Top 10\")\n",
    "    for line in sorted_results[:10]:\n",
    "        print(\"prescision score: \", line[0][1], \"for\", line[1], \"recall: \", line[0][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Declae the stemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the dataset from sklearn\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle ='true')\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle ='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n",
      "7532\n"
     ]
    }
   ],
   "source": [
    "#Confirm the length of the train and test datasets\n",
    "print(len(twenty_train.data))\n",
    "print(len(twenty_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 4, ..., 3, 1, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are as the name suggests twenty different categories for this dataset\n",
    "twenty_train.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start with the code directly from sklearns page for my baseline, just with modified huber instead in this exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='modified_huber', penalty='l2', alpha=1e-3,\n",
    "                       random_state=42, max_iter=5, tol=None))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note though, my problem is defined slightly differently then the baseline sklearn example, namely I am only intrested in tested is this chunk of writing a part of class X or not, a binary question. It is therefore neccisarry for me to create a modified dataset before fitting and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To create a modified dataset,\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "#Go through testing this approach, by changing class 0 to be 1, otherwise change to 0\n",
    "for train_entry in twenty_train.target:\n",
    "    if (train_entry == 0):\n",
    "        y_train.append(1)\n",
    "    else:\n",
    "        y_train.append(0)\n",
    "        \n",
    "for test_entry in twenty_test.target:\n",
    "    if (test_entry == 0):\n",
    "        y_test.append(1)\n",
    "    else:\n",
    "        y_test.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I for initial testing, create a modified y_train and y_test where all instances of class 0 becomes class 1, and everything else becomes class 0, turning the problem into one of binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ty='l2', power_t=0.5, random_state=42,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(twenty_train.data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96893255443441317"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now lets run our prediction on the test data and see how we do\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "np.mean(predicted == y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright that seems like a pretty good result, though we are going to want to take a closer look, as the mean could be misleading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      7213\n",
      "          1       0.91      0.29      0.45       319\n",
      "\n",
      "avg / total       0.97      0.97      0.96      7532\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7204,    9],\n",
       "       [ 225,   94]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out both the metric report, and the confusion matrix\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "metrics.confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright so as expected, what this classifier does is gets a good score by labelling almost everything as not class X. This can be seen in the recall score of .07... which is quite bad. So in essence, of the 319 instances of class 0, 297 were predicted wrong, and only 22 were right. What the classifier did well though, is only predicted 2 instances incorrectly.\n",
    "\n",
    "Let's now see if we can get better results by training the model with less instances of not class X. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "data = zip(twenty_train.data, twenty_train.target)\n",
    "\n",
    "#First add just all instances of the class\n",
    "for entry, label in data:\n",
    "    if (label == 0):\n",
    "        X_train.append(entry)\n",
    "        y_train.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how large this class is\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now test the approach with a ratio of say 4\n",
    "amount = len(X_train) * 4\n",
    "count = 0\n",
    "\n",
    "data = zip(twenty_train.data, twenty_train.target)\n",
    "\n",
    "#Next we will randomly add from the remaining test data by adding the first len(X_train * 4)\n",
    "for entry, label in data:\n",
    "    if count < amount:\n",
    "        if (label != 0):\n",
    "            X_train.append(entry)\n",
    "            y_train.append(0)\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976633032395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      7213\n",
      "          1       0.73      0.71      0.72       319\n",
      "\n",
      "avg / total       0.98      0.98      0.98      7532\n",
      "\n",
      "[[7131   82]\n",
      " [  94  225]]\n"
     ]
    }
   ],
   "source": [
    "#Now fit and classify\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "print(np.mean(predicted == y_test))\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "print(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, this is starting to look a lot better. We will now use the helper functions create_test_labels, and create_train_set, as we have gone manually through the steps and see that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.71884984025559118, 0.73289902280130292, 0.70532915360501569)\n"
     ]
    }
   ],
   "source": [
    "#A quick test of the functions, on class 1 this time, and a ratio of 5\n",
    "y_test = create_test_labels(0, twenty_test.target)\n",
    "X_train, y_train = create_train_set(0, 4, twenty_train.data, twenty_train.target)\n",
    "print(get_metrics(text_clf, X_train, twenty_test.data, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the most important metric at this point is the precision and recall score of class X, I set up the function get_metrics to return the f1 score, which gets at both of those metrics, as well as oth individually. Before changing the classifier, I want to first take a look at whats going on between the relationship between precision and recall as the training data ratio changes.\n",
    "\n",
    "Additionally, I set up a function earlier that calculates the average F1 score over every class, for each possible ratio, with an option to change the text classifier, we will now run that function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step:  1\n",
      "At step:  2\n",
      "At step:  3\n",
      "At step:  4\n",
      "At step:  5\n",
      "At step:  6\n",
      "At step:  7\n",
      "At step:  8\n",
      "At step:  9\n",
      "At step:  10\n"
     ]
    }
   ],
   "source": [
    "#Run the function,\n",
    "f1_ratios, precision_ratios, recall_ratios = get_average_f1_ratios(text_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably this process is fairly intensive to run, which means it most likely won't be practical to re-run in full as we move onto the next step of refining/redefining the classifier used. Hopefully though, what running this more intesive search will provide is a usable ratio to use for the remainder of the expiriment. We are of course then operating under the assumption that the results will not change too dramatically over different classifiers. It should be also noted that I restricted the search to ratios 1-10, as that covers all reasonable cases, as well as the maximum ratio becomes unpredicatable around 13-14 when it will trigger out of bound errors. \n",
    "\n",
    "Now, we will plot the results to give an idea of what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEeCAYAAACt7uMeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCeEJxTnnXEL8P2nwTJHJ24+iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c2a868550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First plot the f1 ratios\n",
    "plt.plot(f1_ratios, label='F1')\n",
    "plt.plot(precision_ratios, label='Precision')\n",
    "plt.plot(recall_ratios, label='Recall')\n",
    "\n",
    "\n",
    "title = \"Avg. F1, precision and recall score over training data ratio\"\n",
    "plt.title(title)\n",
    "plt.xlabel(\"Data Ratio\", fontsize=14)\n",
    "plt.ylabel(\"Score\", fontsize=14)\n",
    "\n",
    "plt.legend(prop={'size': 12})\n",
    "\n",
    "plt.tick_params(labelsize=14) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the graph above shows, it appears a ratio of around 2 provides us with the best F1 score. The graph also contains other information though, like the recall spike at ratio 1, and precision continuing to increase as ratio falls.\n",
    "\n",
    "Lets look again the pipeline as defined now\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3,\n",
    "                       random_state=42, max_iter=5, tol=None))])\n",
    "                       \n",
    "We can test using a grid search to see if we can find better parameters, though this is also very intensive, so we won't attempt to run it on the range of different classes and ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try the following different parameter options\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf__alpha': (1e-2, 1e-3)}\n",
    "\n",
    "#Define the grid search classifier\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test this on say class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = create_test_labels(0, twenty_test.target)\n",
    "X_train, y_train = create_train_set(1, 2, twenty_train.data, twenty_train.target)\n",
    "\n",
    "gs_clf = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0023474178403755869, 0.001876172607879925, 0.003134796238244514)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(gs_clf, X_train, twenty_test.data, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well something looks very off there... in any case grid search in our case doesn't even represent the best solution in terms of F1 score, so it is safe to default to the previously defined classifier. \n",
    "\n",
    "Note: When I tried using a custom defined metric of F1 score, sklearn would give me strange errors, so I define my own grid search togive more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I'm just gonna redefine our initial pipeline as it worked well\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='modified_huber', penalty='l2', alpha=1e-3,\n",
    "                       random_state=42, max_iter=5, tol=None))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I've switched back to the previous pipeline, since the results were good. That being said, the last thing I would like to try is taking a look at the twenty news dataset under the same preproccessing steps as the rest of the data, to see what type of an effect this has. Note: after considering turning the newsgroup data into discrete sentences, I decided it would be better to not. The reason being, the label extends over the whole 500 word chunk rather then each sentence, so it would therefore label a lot of the sentences that were not about the subject as about the subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Call the preproc function to create a preprocessed version of each\n",
    "twenty_train_data_proc = preproc(twenty_train.data)\n",
    "twenty_test_data_proc = preproc(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.733652312599681, 0.74675324675324672, 0.72100313479623823)\n"
     ]
    }
   ],
   "source": [
    "#And lets now run the test from earlier again, but with the processed data\n",
    "y_test = create_test_labels(0, twenty_test.target)\n",
    "X_train, y_train = create_train_set(0, 4, twenty_train_data_proc, twenty_train.target)\n",
    "print(get_metrics(text_clf, X_train, twenty_test_data_proc, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results above, to (0.71884984025559118, 0.73289902280130292, 0.70532915360501569),\n",
    "Where the first number is the F1 score, the second is precision and the third is recall. So after running the pre-proc steps, the performance actually increased a little bit, not much, but a little. \n",
    "\n",
    "Now with a baseline metric of performance established we ar e ready to test using unlabelled data in a few different ways.\n",
    "\n",
    "The options are:\n",
    "1. From scratch, using just keyword searches to build the initial training set.\n",
    "2. From scratch, by training a simple classifier.\n",
    "3. As a supplement to a supervised learning problem, using keywords from labelled data.\n",
    "4. As a supplement to a supervised learning problem, using a modified classifier.\n",
    "\n",
    "I will proceed through testing exploring each option in turn. Starting with number 1, it is fairly ambigious where to begin, and as the problem is defined we are quite unlikely to get results better then our baseline. This is to be expected though, as the intended role of option 1 is not to preform better then a supervised learning problem, but merely to preform better then just a keyword search. Since that is the case, metrics for this option, and for number 2 for that matter, should be evaluated with the training set, as well as the test set, and in comparison to a comprable key word search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin lets choose a subject, say class 1, comp.graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject:,  comp.graphics\n",
      "From: jgreen@amber (Joe Green)\n",
      "Subject: Re: Weitek P9000 ?\n",
      "Organization: Harris Computer Systems Division\n",
      "Lines: 14\n",
      "Distribution: world\n",
      "NNTP-Posting-Host: amber.ssd.csd.harris.com\n",
      "X-Newsreader: TIN [version 1.1 PL9]\n",
      "\n",
      "Robert J.C. Kyanko (rob@rjck.UUCP) wrote:\n",
      "> abraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\n",
      "> > Anyone know about the Weitek P9000 graphics chip?\n",
      "> As far as the low-level stuff goes, it looks pretty nice.  It's got this\n",
      "> quadrilateral fill command that requires just the four points.\n",
      "\n",
      "Do you have Weitek's address/phone number?  I'd like to get some information\n",
      "about this chip.\n",
      "\n",
      "--\n",
      "Joe Green\t\t\t\tHarris Corporation\n",
      "jgreen@csd.harris.com\t\t\tComputer Systems Division\n",
      "\"The only thing that really scares me is a person with no sense of humor.\"\n",
      "\t\t\t\t\t\t-- Jonathan Winters\n",
      "\n",
      "From: ab@nova.cc.purdue.edu (Allen B)\n",
      "Subject: Re: TIFF: philosophical significance of 42\n",
      "Organization: Purdue University\n",
      "Lines: 39\n",
      "\n",
      "In article <prestonm.735400848@cs.man.ac.uk> prestonm@cs.man.ac.uk (Martin  \n",
      "Preston) writes:\n",
      "> Why not use the PD C library for reading/writing TIFF files? It took me a\n",
      "> good 20 minutes to start using them in your own app.\n",
      "\n",
      "I certainly do use it whenever I have to do TIFF, and it usually works\n",
      "very well.  That's not my point.  I'm >philosophically< opposed to it\n",
      "because of its complexity.\n",
      "\n",
      "This complexity has led to some programs' poor TIFF writers making\n",
      "some very bizarre files, other programs' inability to load TIFF\n",
      "images (though they'll save them, of course), and a general\n",
      "inability to interchange images between different environments\n",
      "despite the fact they all think they understand TIFF.\n",
      "\n",
      "As the saying goes, \"It's not me I'm worried about- it's all the\n",
      ">other<  assholes out there!\"  I've had big trouble with misuse and\n",
      "abuse of TIFF over the years, and I chalk it all up to the immense (and\n",
      "unnecessary) complexity of the format.\n",
      "\n",
      "In the words of the TIFF 5.0 spec, Appendix G, page G-1 (capitalized\n",
      "emphasis mine):\n",
      "\n",
      "\"The only problem with this sort of success is that TIFF was designed\n",
      "to be powerful and flexible, at the expense of simplicity.  It takes a\n",
      "fair amount of effort to handle all the options currently defined in\n",
      "this specification (PROBABLY NO APPLICATION DOES A COMPLETE JOB),\n",
      "and that is currently the only way you can be >sure< that you will be\n",
      "able to import any TIFF image, since there are so many\n",
      "image-generating applications out there now.\"\n",
      "\n",
      "\n",
      "If a program (or worse all applications) can't read >every< TIFF\n",
      "image, that means there are some it won't- some that I might have to\n",
      "deal with.  Why would I want my images to be trapped in that format?  I\n",
      "don't and neither should anyone who agrees with my reasoning- not\n",
      "that anyone does, of course! :-)\n",
      "\n",
      "ab\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Subject:, \", twenty_train.target_names[1])\n",
    "\n",
    "#And lets print a few examples, I use the not proccesed one for readability\n",
    "for i in range(1,25):\n",
    "    if (twenty_train.target[i] == 1):\n",
    "        print(twenty_train.data[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 involves first looking at the subject matter, and generating some keywords. I'll do my best to brainstorm some that are both broad enough to show up, and specific enough it be associated with computer graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' graphic chip', ' graphic workstat', ' imag code', ' digit imag', ' tiff', ' gnu plot', ' comput graphic', ' graphic card', ' 3d graphic', ' thin algorithm', ' thin imag', ' cgi', ' textur map', ' curv separ', ' imag process']\n"
     ]
    }
   ],
   "source": [
    "comp_graphics_key_words = [\"graphics chip\", \"graphic workstation\", \"image coding\",\n",
    "                           \"digital imaging\", \" tiff \", \"gnu plot\", \"computer graphics\", \"graphics card\",\n",
    "                           \"3d graphics\", \"thinning algorithm\", \"thinned image\", \" cgi \", \"texture mapping\", \n",
    "                           \"curve separation\", \"image processing\"]\n",
    "\n",
    "#Store pre-proc keywords here\n",
    "comp_keys = []\n",
    "\n",
    "#Go through each key and stem\n",
    "for key in comp_graphics_key_words:\n",
    "    words = nltk.word_tokenize(key.lower())\n",
    "\n",
    "    ent = \"\"\n",
    "\n",
    "        #Stem each word, and re add to entry\n",
    "    for word in words:\n",
    "        word = stemmer.stem(word)\n",
    "\n",
    "        ent = ent + \" \" + word\n",
    "        \n",
    "    comp_keys.append(ent)\n",
    "\n",
    "print(comp_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is of course one large step missing here before these keywords are usable, and this is creating an unlabelled set of data to search through. In preprocessing.ipynb, I prepare each individual dataset for use here. For the scope of this problem I will create this set from the first redditTextBlock of 10 million comments split into sentences, and will merge that with the news, blog and twitter sample text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_paths = ['data/redditTextBlock1Proc.pkl', 'data/courseraBlogsProc.pkl', 'data/courseraTwitterProc.pkl',\n",
    "              'data/courseraNewsProc.pkl']\n",
    "\n",
    "#Use the createCorpus function to create a Corpus based on the read paths\n",
    "corpus = createCorpus(read_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32266806"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the length of the corpus created\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now use the createQuickTrainingData function defined earlier to search through the Corpus, getting all instances of a line where a keyword is present, as well as, adding based on the ratio given, an amount of negative instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = createQuickTrainingData(comp_keys, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define our test set to include all of the avaliable labeled data, both training and test.\n",
    "X_test = twenty_train_data_proc + twenty_test_data_proc\n",
    "y_test = create_test_labels(1,list(twenty_train.target) + list(twenty_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n",
      "18846\n"
     ]
    }
   ],
   "source": [
    "#Sanity check, make sure X_test, and y_test are the same\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97     17873\n",
      "          1       0.39      0.22      0.28       973\n",
      "\n",
      "avg / total       0.93      0.94      0.93     18846\n",
      "\n",
      "[[17539   334]\n",
      " [  762   211]]\n"
     ]
    }
   ],
   "source": [
    "#Redefine the pipeline just to again see the current settings\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()), \n",
    "                     ('clf', SGDClassifier(loss='modified_huber', penalty='l2', alpha=1e-3,\n",
    "                       random_state=42, max_iter=5, tol=None))])\n",
    "\n",
    "text_clf.fit(X,y)\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "print(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright interesting, so from just a 10ish keywords we are able to get .4 precision, and .20 recall... alright that is pretty bad, but at this step we are not exactly expecting perfect results. \n",
    "\n",
    "Lets compare these numbers to how just a keyword search performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = []\n",
    "\n",
    "#Search through the test set, and mark as 1 if the keyword is found otherwise mark 0\n",
    "for line in X_test:\n",
    "        found = False\n",
    "        \n",
    "        for key in comp_keys:\n",
    "            if (key in line) and (not found):\n",
    "                \n",
    "                #Add 1 if found\n",
    "                predicted.append(1)\n",
    "                found = True\n",
    "        \n",
    "        #If not found, add 0\n",
    "        if not found:\n",
    "            predicted.append(0)\n",
    "\n",
    "#Lastly, a sanity check\n",
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.97     17873\n",
      "          1       0.60      0.18      0.28       973\n",
      "\n",
      "avg / total       0.94      0.95      0.94     18846\n",
      "\n",
      "[[17757   116]\n",
      " [  796   177]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predicted))\n",
    "print(metrics.confusion_matrix(y_test, predicted))\n",
    "\n",
    "base_line = metrics.f1_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so the baseline keyword search actually performed a little bit better... though this is before any finetuning to the classifier I trained on the corpus data, so that will constitute the next step. This is also notably after looking at the testing data, which in a way is cheating, since to gather key words I looked at examples of key words. Regardless, it sets a good baseline, to try and beat with just a keyword search.\n",
    "\n",
    "\n",
    "A few things I would like to expiriment with are, a different loss function for the SGD classifier,\n",
    "different ratios of training data, and use of ngram range in CountVectorizer, and setting max_features.\n",
    "The different loss functions for this task could be - ‘hinge’, ‘log’, ‘modified_huber’, ‘squared_hinge’, ‘perceptron’. \n",
    "\n",
    "Let's try 'hinge','modified huber' and 'perceptron' for the loss functions.\n",
    "\n",
    "Also note, I will run my own version of a grid search defined earlier to give myself more control over the metric used to evaluate. Also note that I shouldn't need to run the search with all the different ratios, I will try 2-7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 / 216\n",
      "50 / 216\n",
      "75 / 216\n",
      "100 / 216\n",
      "125 / 216\n",
      "150 / 216\n",
      "175 / 216\n",
      "200 / 216\n"
     ]
    }
   ],
   "source": [
    "#Params to search over\n",
    "loss_functions = ['hinge','modified_huber','squared_hinge']\n",
    "n_grams = [(1,1), (1,2),(1,3)]\n",
    "max_features_options = [None, 300, 500, 1000]\n",
    "ratio_range = [2,8]\n",
    "\n",
    "results = GridSearch(loss_functions, n_grams, max_features_options, ratio_range, comp_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "f1 score:  0.367803837953 for [3, 'modified_huber', (1, 3), 300]\n",
      "f1 score:  0.367521367521 for [3, 'modified_huber', (1, 2), 300]\n",
      "f1 score:  0.363304981774 for [5, 'modified_huber', (1, 1), 300]\n",
      "f1 score:  0.36125 for [6, 'modified_huber', (1, 1), 300]\n",
      "f1 score:  0.357906584131 for [3, 'modified_huber', (1, 2), 500]\n",
      "f1 score:  0.357824427481 for [3, 'modified_huber', (1, 1), 300]\n",
      "f1 score:  0.357548240636 for [3, 'modified_huber', (1, 3), 500]\n",
      "f1 score:  0.356965174129 for [4, 'modified_huber', (1, 2), 300]\n",
      "f1 score:  0.356027482823 for [4, 'modified_huber', (1, 3), 300]\n",
      "f1 score:  0.35261707989 for [4, 'modified_huber', (1, 1), 300]\n",
      "Bottom 5\n",
      "f1 score:  0.0138476755687 for [6, 'hinge', (1, 2), None]\n",
      "f1 score:  0.01001001001 for [5, 'hinge', (1, 3), None]\n",
      "f1 score:  0.00811359026369 for [7, 'hinge', (1, 3), None]\n",
      "f1 score:  0.00807265388496 for [6, 'hinge', (1, 3), None]\n",
      "f1 score:  0.008 for [7, 'hinge', (1, 2), None]\n"
     ]
    }
   ],
   "source": [
    "#Save the best result to full_corpus and print the rest\n",
    "full_corpus = printF1(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so the modified huber loss function preformed far better, with every single one in the top 10 having loss modified huber. In addition, the max features in the top 20 are around 300-500, with None at the bottom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "precision score:  0.582210242588 for [7, 'modified_huber', (1, 3), 500] with recall:  0.221993833505\n",
      "precision score:  0.57957957958 for [7, 'modified_huber', (1, 3), 1000] with recall:  0.198355601233\n",
      "precision score:  0.579411764706 for [7, 'modified_huber', (1, 2), 1000] with recall:  0.20246659815\n",
      "precision score:  0.574468085106 for [7, 'modified_huber', (1, 2), 500] with recall:  0.221993833505\n",
      "precision score:  0.573604060914 for [6, 'modified_huber', (1, 3), 500] with recall:  0.232271325797\n",
      "precision score:  0.562015503876 for [5, 'hinge', (1, 2), 500] with recall:  0.149023638232\n",
      "precision score:  0.560885608856 for [5, 'hinge', (1, 3), 500] with recall:  0.156217882837\n",
      "precision score:  0.558024691358 for [6, 'modified_huber', (1, 2), 500] with recall:  0.232271325797\n",
      "precision score:  0.557422969188 for [6, 'modified_huber', (1, 3), 1000] with recall:  0.204522096608\n",
      "precision score:  0.557184750733 for [4, 'hinge', (1, 3), 300] with recall:  0.195272353546\n",
      "Bottom 10\n",
      "precision score:  0.0491325819932 for [6, 'squared_hinge', (1, 3), 300] with recall:  0.79753340185\n",
      "precision score:  0.0491243323811 for [4, 'squared_hinge', (1, 1), 300] with recall:  0.812949640288\n",
      "precision score:  0.0490410293761 for [5, 'squared_hinge', (1, 2), 300] with recall:  0.830421377184\n",
      "precision score:  0.0487666034156 for [5, 'squared_hinge', (1, 1), 300] with recall:  0.792394655704\n",
      "precision score:  0.0485974174671 for [7, 'squared_hinge', (1, 1), 300] with recall:  0.7852004111\n",
      "precision score:  0.0485198918987 for [7, 'squared_hinge', (1, 3), 300] with recall:  0.793422404933\n",
      "precision score:  0.0484145495808 for [7, 'squared_hinge', (1, 2), 300] with recall:  0.789311408016\n",
      "precision score:  0.0483445648989 for [7, 'squared_hinge', (1, 1), 1000] with recall:  0.678314491264\n",
      "precision score:  0.0480915525567 for [7, 'squared_hinge', (1, 3), 500] with recall:  0.74717368962\n",
      "precision score:  0.0480673606047 for [7, 'squared_hinge', (1, 2), 500] with recall:  0.745118191161\n"
     ]
    }
   ],
   "source": [
    "#Try sorting by precision, just as a comparison to the high precision seen in the keyword search\n",
    "sorted_results = sorted(results,key=lambda x: (x[0][1]), reverse=True)\n",
    "\n",
    "print(\"Top 10\")\n",
    "for line in sorted_results[:10]:\n",
    "    print(\"precision score: \", line[0][1], \"for\", line[1], \"with recall: \", line[0][2])\n",
    "    \n",
    "print(\"Bottom 10\")\n",
    "for line in sorted_results[-10:]:\n",
    "    print(\"precision score: \", line[0][1], \"for\", line[1],  \"with recall: \", line[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the precision and recall scores, as expected, with high precision comeslow recall, and vice versa.\n",
    "\n",
    "In any case the winner in this round appears to be 'modified_huber' loss, 300 max_features, (1,2) or (1,3) n-gram,\n",
    "3-4 ratio, these approaches yielfing f1 scores around .36, compared to the simple keyword search, which yielded .28. \n",
    "\n",
    "The next question to consider is, how does this change as the 'corpus' of documents changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 / 54\n",
      "50 / 54\n"
     ]
    }
   ],
   "source": [
    "#Read in only the news samples this time\n",
    "read_paths = ['data/courseraNewsProc.pkl']\n",
    "\n",
    "corpus = createCorpus(read_paths)\n",
    "\n",
    "#Further we can refine the search by only using modified huber, and different max_features\n",
    "#The other settings stay the same\n",
    "loss_functions = ['modified_huber']\n",
    "max_features_options = [200, 300, 500]\n",
    "\n",
    "results = GridSearch(loss_functions, n_grams, max_features_options, ratio_range, comp_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "f1 score:  0.379657007688 for [4, 'modified_huber', (1, 1), 300]\n",
      "f1 score:  0.372121212121 for [4, 'modified_huber', (1, 3), 500]\n",
      "f1 score:  0.371779141104 for [4, 'modified_huber', (1, 2), 500]\n",
      "f1 score:  0.371747211896 for [4, 'modified_huber', (1, 1), 500]\n",
      "f1 score:  0.369770580297 for [5, 'modified_huber', (1, 2), 500]\n",
      "f1 score:  0.368563685637 for [5, 'modified_huber', (1, 3), 500]\n",
      "f1 score:  0.36784409257 for [2, 'modified_huber', (1, 1), 300]\n",
      "f1 score:  0.365577051368 for [5, 'modified_huber', (1, 1), 500]\n",
      "f1 score:  0.363636363636 for [2, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.363400389358 for [3, 'modified_huber', (1, 2), 300]\n",
      "Bottom 5\n",
      "f1 score:  0.0040733197556 for [6, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.00406504065041 for [6, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.0 for [7, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.0 for [7, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.0 for [7, 'modified_huber', (1, 3), 200]\n"
     ]
    }
   ],
   "source": [
    "#Save the best score, and print the rest\n",
    "just_news = printF1(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 / 54\n",
      "50 / 54\n"
     ]
    }
   ],
   "source": [
    "#Now test everything, but without the news\n",
    "read_paths = ['data/redditTextBlock1Proc.pkl', 'data/courseraBlogsProc.pkl', 'data/courseraTwitterProc.pkl']\n",
    "\n",
    "corpus = createCorpus(read_paths)\n",
    "\n",
    "results = GridSearch(loss_functions, n_grams, max_features_options, ratio_range, comp_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "f1 score:  0.375291375291 for [4, 'modified_huber', (1, 3), 300]\n",
      "f1 score:  0.375145180023 for [4, 'modified_huber', (1, 2), 300]\n",
      "f1 score:  0.369982547993 for [2, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.368898978434 for [3, 'modified_huber', (1, 3), 300]\n",
      "f1 score:  0.368289637953 for [3, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.367439231204 for [3, 'modified_huber', (1, 2), 300]\n",
      "f1 score:  0.367398119122 for [3, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.366226912929 for [4, 'modified_huber', (1, 1), 300]\n",
      "f1 score:  0.365748709122 for [2, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.364563416189 for [4, 'modified_huber', (1, 3), 200]\n",
      "Bottom 5\n",
      "f1 score:  0.230878186969 for [7, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.193650793651 for [6, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.192675159236 for [6, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.192276088743 for [7, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.188429752066 for [7, 'modified_huber', (1, 3), 200]\n"
     ]
    }
   ],
   "source": [
    "#Save the best score, and print the rest\n",
    "without_news = printF1(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 / 54\n",
      "50 / 54\n"
     ]
    }
   ],
   "source": [
    "#Now lets try testing with all the data, but randomly removing half\n",
    "read_paths = ['data/redditTextBlock1Proc.pkl', 'data/courseraBlogsProc.pkl', 'data/courseraTwitterProc.pkl',\n",
    "              'data/courseraNewsProc.pkl']\n",
    "\n",
    "corpus = createCorpus(read_paths)\n",
    "\n",
    "#shuffle then randomly delete half the corpus\n",
    "random.shuffle(corpus)\n",
    "\n",
    "for x in range(int(len(corpus)/2)):\n",
    "    corpus.pop()\n",
    "\n",
    "results = GridSearch(loss_functions, n_grams, max_features_options, ratio_range, comp_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "f1 score:  0.372943327239 for [4, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.372572815534 for [4, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.363432417274 for [6, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.362107623318 for [6, 'modified_huber', (1, 1), 300]\n",
      "f1 score:  0.361283643892 for [4, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.359759431383 for [3, 'modified_huber', (1, 3), 300]\n",
      "f1 score:  0.359669811321 for [6, 'modified_huber', (1, 1), 500]\n",
      "f1 score:  0.359490274983 for [5, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.359488035615 for [3, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.358738501971 for [6, 'modified_huber', (1, 2), 500]\n",
      "Bottom 5\n",
      "f1 score:  0.237113402062 for [6, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.236861584012 for [6, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.236220472441 for [7, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.208538587849 for [7, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.208538587849 for [7, 'modified_huber', (1, 3), 200]\n"
     ]
    }
   ],
   "source": [
    "#Save the best score and print the rest\n",
    "half_corpus = printF1(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have run the search over a few different options, we can make a quick graph to see some comparisons of the best scores for each option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt4AAAGrCAYAAAD3k5CwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAALKN4AALDA3wHeUkk60e16xgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b1777f908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "plt.bar(1, base_line, label='1 - Base Line')\n",
    "plt.bar(2, full_corpus, label='2 - Full Corpus')\n",
    "plt.bar(3, just_news, label='3 - Just News')\n",
    "plt.bar(4, without_news, label='4 - Without News')\n",
    "plt.bar(5, half_corpus, label = \"5 - Half Corpus\")\n",
    "\n",
    "title = \"Top F1 scores for classifiers trained on different Corpus\"\n",
    "plt.title(title)\n",
    "plt.ylabel(\"F1 Scores\", fontsize=14)\n",
    "\n",
    "plt.legend(prop={'size': 12})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright moving on, Technique 2, building a classifier from scratch doesn't make as much sense to test on this dataset, so I will move on to 3.Technique 3 involves again splitting the testing data into train split, and then using a look at the test set to generate key words. We will first try the most naive approach possible only looking at word frequency in class X, and then move onto applying tf-idf, and viewing the whole training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Redfine X_train and y_test, lets say with class 9 this time, ratio of 4\n",
    "y_test = create_test_labels(9, twenty_test.target)\n",
    "X_train, y_train = create_train_set(9, 4, twenty_train_data_proc, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = zip (X_train, y_train)\n",
    "\n",
    "class_X = []\n",
    "not_class_X = []\n",
    "\n",
    "for line,label in train_data:\n",
    "    if (label == 1):\n",
    "        class_X.append(line)\n",
    "    else:\n",
    "        not_class_X.append(line)\n",
    "        \n",
    "len(class_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the word count for every word in class X\n",
    "\n",
    "#Use a counter from python collections to get a quick word count\n",
    "cnt_class_X = collections.Counter()\n",
    "\n",
    "for line in class_X:\n",
    "    words = nltk.word_tokenize(line)\n",
    "    \n",
    "    for word in words:\n",
    "        cnt_class_X[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 6617),\n",
       " ('.', 5964),\n",
       " ('>', 5930),\n",
       " ('--', 5753),\n",
       " ('the', 5616),\n",
       " (':', 4774),\n",
       " (')', 2673),\n",
       " ('a', 2439),\n",
       " ('to', 2346),\n",
       " ('(', 2189),\n",
       " ('in', 2164),\n",
       " ('of', 2106),\n",
       " ('and', 2105),\n",
       " ('@', 1985),\n",
       " ('i', 1906),\n",
       " ('is', 1477),\n",
       " ('that', 1417),\n",
       " ('?', 1159),\n",
       " ('he', 1140),\n",
       " ('!', 1123)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out the most common 20 words\n",
    "cnt_class_X.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, it seems pretty clear from our naive first attempt that taking into account term frequency is almost invaluable, with all 20 of the top 'words' being extremly generic, and revealing no pertinent class information. Before using any of sklearns built into tf-idf, lets try using a neat feature of Counter objects, which lets us subtract the counts of one counter from another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt_not_class_X = collections.Counter()\n",
    "\n",
    "for line in not_class_X:\n",
    "    words = nltk.word_tokenize(line)\n",
    "    \n",
    "    for word in words:\n",
    "        cnt_not_class_X[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('>', 36428),\n",
       " (',', 35473),\n",
       " ('the', 30717),\n",
       " ('.', 30006),\n",
       " (':', 25031),\n",
       " ('--', 20938),\n",
       " (')', 16026),\n",
       " ('(', 15924),\n",
       " ('to', 15243),\n",
       " ('of', 14833),\n",
       " ('@', 13401),\n",
       " ('a', 12817),\n",
       " ('and', 12209),\n",
       " ('i', 10672),\n",
       " ('in', 10060),\n",
       " ('is', 9464),\n",
       " ('ax', 9107),\n",
       " ('?', 8689),\n",
       " (\"''\", 8282),\n",
       " ('that', 8276)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Might as well take a peak the not_x most common as well..\n",
    "cnt_not_class_X.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look awfully simmilar, so the next reasonable step is to subtract these counts from the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt_class_X.subtract(cnt_not_class_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('basebal', 289),\n",
       " ('team', 273),\n",
       " ('pitch', 265),\n",
       " ('game', 239),\n",
       " ('player', 221),\n",
       " ('hit', 210),\n",
       " ('win', 199),\n",
       " ('cub', 164),\n",
       " ('brave', 156),\n",
       " ('season', 149),\n",
       " ('score', 140),\n",
       " ('pitcher', 137),\n",
       " ('philli', 137),\n",
       " ('leagu', 128),\n",
       " ('hitter', 127),\n",
       " ('alomar', 116),\n",
       " ('fan', 111),\n",
       " ('bat', 106),\n",
       " ('yanke', 103),\n",
       " ('sox', 103)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_class_X.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.sport.baseball'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look a lot better, and is clear now that class 9 is about baseball, as confirmed by checking the target names. It also reveals a large potential flaw, where by only using one word, if we were to use these key words in a general search of the corpus we are almost gaurenteed to turn up a great deal of unrelated sentences. For example 'fan', doesn't imply only baseball, it just means that within the twenty news dataset, and our limited training set, fan ussually shows up with baseball. This raises two issues to deal with before actually testing, making sure the word is actually specific to the subject and can't be easily generalized, and related, the issue of 1-grams vs. n-grams. The first of these issues is far harder to solve, but by dealing with the second, we may reduce it's sway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try with 2-gram first\n",
    "cnt_class_X = get_N_Gram_Count(class_X, 2)\n",
    "cnt_not_class_X = get_N_Gram_Count(not_class_X, 2)\n",
    "\n",
    "cnt_class_X.subtract(cnt_not_class_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' the brave', 94),\n",
       " (' last year', 89),\n",
       " (' 0 0', 87),\n",
       " (' game ,', 80),\n",
       " (' this year', 76),\n",
       " (\" he 's\", 63),\n",
       " (' the cub', 62),\n",
       " (' home run', 59),\n",
       " (' hall of', 59),\n",
       " (' red sox', 52),\n",
       " (' @ cs.cornell.edu', 52),\n",
       " (' in basebal', 52),\n",
       " (' the philli', 51),\n",
       " (' a team', 51),\n",
       " (' basebal .', 49),\n",
       " (' of fame', 49),\n",
       " (' the team', 46),\n",
       " (' win the', 46),\n",
       " (' basebal player', 45),\n",
       " (' year .', 44)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_class_X.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, these seem to be a little more what we are looking for, but we still can't quite just plug these results in blind, e.g. '0 0' doesn't seem to have much to do with baseball, and 'game ,' doesn't have much information to it. Let's just take a look at 3-gram, though I doubt it will be much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt_class_X = get_N_Gram_Count(class_X, 3)\n",
    "cnt_not_class_X = get_N_Gram_Count(not_class_X, 3)\n",
    "\n",
    "cnt_class_X.subtract(cnt_not_class_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' 0 0 0', 53),\n",
       " (' hall of fame', 50),\n",
       " (' the hall of', 39),\n",
       " (' tedward @ cs.cornell.edu', 38),\n",
       " (' ( edward [', 37),\n",
       " (' ] fischer )', 37),\n",
       " (' edward [ ted', 36),\n",
       " (' [ ted ]', 36),\n",
       " (' ted ] fischer', 36),\n",
       " (' jewish basebal player', 35),\n",
       " (' basebal player ?', 34),\n",
       " (' cs.cornell.edu ( edward', 34),\n",
       " (' @ cs.cornell.edu (', 33),\n",
       " (' re : jewish', 32),\n",
       " (' : jewish basebal', 32),\n",
       " (' cub suck cub', 32),\n",
       " (' mss @ netcom.com', 30),\n",
       " (' this year .', 30),\n",
       " (' ( roger lustig', 30),\n",
       " (' roger lustig )', 30)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_class_X.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it's safe to say the 3-gram starts returning some really un-usable keyword. While it would ideally be avoided, I think this approach will also require human input at this step. I will generate one's I believe to be useful from the various printed lists, this atleast helps the human come up with keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What I could come up with from what was printed above, pretty much just baseball, and different teams.\n",
    "baseball_key_words = ['basebal', 'the cubs', 'red sox', 'major leagu', 'the yanke', 'the philli', 'the brave']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding these new instances, we have two options for introducing more instances of not class X to training data, the first is add more from the twenty news group data, and the second is to introduce examples from the corpus. As at least in this case the number of instances found is more than our whole training set, it seems we are forced to add from the corpus. Note: we already have the trainQuickClassifier avaliable to grab us instances, so me might as well add both at once to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53045"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Search the corpus for all instances of the keywords, and get counter examples as well\n",
    "#Use ratio 4 like above\n",
    "lines_with_key, y = createQuickTrainingData(baseball_key_words, 4)\n",
    "len(lines_with_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in lines_with_key:\n",
    "    X_train.append(line)\n",
    "for line in y:\n",
    "    y_train.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56030"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the new size of the training set\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = twenty_test_data_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now that we have our new classifier, it is time to test it on X_test, and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.58022690437601299, 0.8136363636363636, 0.45088161209068012)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets use some of the information we found above when defining our initial text clf\n",
    "#Specifically we are already using ratio 4, lets use 'modified_huber', and ngram = (1,2), and lets start with\n",
    "#max_features = 1000\n",
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,2), max_features=1000)),('tfidf', TfidfTransformer()),\n",
    "                             ('clf', SGDClassifier(loss='modified_huber', penalty='l2', alpha=1e-3,\n",
    "                               random_state=22, max_iter=10))])\n",
    "\n",
    "\n",
    "get_metrics(text_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frankly these are not great results, but before we come to any conclusions I think it would be worthwhile to modify the GridSearch function to work with this approach, and to preform a broader test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 / 54\n",
      "50 / 54\n"
     ]
    }
   ],
   "source": [
    "#Note: the ModifiedGridSearch now takes the extra param class_num and class_keys, lets define the search params\n",
    "loss_functions = ['modified_huber'] #Only going to try modified huber\n",
    "n_grams = [(1,1),(1,2),(1,3)]\n",
    "max_features_options = [None, 500, 1000]\n",
    "ratio_range = [1,7]\n",
    "\n",
    "#And run it\n",
    "results = ModifiedGridSearch(loss_functions, n_grams, max_features_options, ratio_range, 9, baseball_key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "f1 score:  0.675642594859 for [2, 'modified_huber', (1, 1), None]\n",
      "f1 score:  0.653846153846 for [2, 'modified_huber', (1, 2), 500]\n",
      "f1 score:  0.653796653797 for [2, 'modified_huber', (1, 3), 500]\n",
      "f1 score:  0.650292397661 for [2, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.647130647131 for [2, 'modified_huber', (1, 2), 1000]\n",
      "f1 score:  0.643031784841 for [2, 'modified_huber', (1, 3), 1000]\n",
      "f1 score:  0.640804597701 for [3, 'modified_huber', (1, 1), None]\n",
      "f1 score:  0.639455782313 for [3, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.635622817229 for [2, 'modified_huber', (1, 1), 500]\n",
      "f1 score:  0.634482758621 for [3, 'modified_huber', (1, 1), 500]\n",
      "Bottom 5\n",
      "f1 score:  0.45652173913 for [6, 'modified_huber', (1, 3), 500]\n",
      "f1 score:  0.415162454874 for [6, 'modified_huber', (1, 2), None]\n",
      "f1 score:  0.394366197183 for [6, 'modified_huber', (1, 3), None]\n",
      "f1 score:  0.337373737374 for [1, 'modified_huber', (1, 2), None]\n",
      "f1 score:  0.258040935673 for [1, 'modified_huber', (1, 3), None]\n"
     ]
    }
   ],
   "source": [
    "#As used above save the best score for each for later plotting\n",
    "baseball = printF1(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a more comprehensive search, we were able to get closer results to the baseline, yet it still falls signifigantly short. It is important to note though, these results are based on only one key word search. I will re-run the search, using stricter margins to increase run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets try with different baseball_keywords... or just basebal\n",
    "baseball_key_words = ['basebal']\n",
    "\n",
    "max_features_options = [200, 500, 1000]  #200 instead of none\n",
    "ratio_range = [2,4]  #Top results all 2 or 3\n",
    "\n",
    "#And re-run it\n",
    "results = ModifiedGridSearch(loss_functions, n_grams, max_features_options, ratio_range, 9, baseball_key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "f1 score:  0.647427854454 for [2, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.632944228275 for [2, 'modified_huber', (1, 3), 1000]\n",
      "f1 score:  0.631168831169 for [2, 'modified_huber', (1, 2), 1000]\n",
      "f1 score:  0.610899873257 for [2, 'modified_huber', (1, 1), 500]\n",
      "f1 score:  0.608955223881 for [3, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.606770833333 for [2, 'modified_huber', (1, 3), 500]\n",
      "f1 score:  0.60103626943 for [2, 'modified_huber', (1, 2), 500]\n",
      "f1 score:  0.574886535552 for [3, 'modified_huber', (1, 2), 1000]\n",
      "f1 score:  0.571428571429 for [3, 'modified_huber', (1, 3), 1000]\n",
      "f1 score:  0.556732223903 for [3, 'modified_huber', (1, 2), 500]\n",
      "Bottom 5\n",
      "f1 score:  0.513812154696 for [2, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.508990318119 for [2, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.478605388273 for [3, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.475409836066 for [3, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.470588235294 for [3, 'modified_huber', (1, 3), 200]\n"
     ]
    }
   ],
   "source": [
    "baseball_less = printF1(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now try running the baseline without any keywords\n",
    "leave_this_blank = []\n",
    "\n",
    "results = ModifiedGridSearch(loss_functions, n_grams, max_features_options, ratio_range, 9, leave_this_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "f1 score:  0.690376569038 for [2, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.685897435897 for [3, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.674468085106 for [3, 'modified_huber', (1, 3), 1000]\n",
      "f1 score:  0.674443266172 for [3, 'modified_huber', (1, 2), 1000]\n",
      "f1 score:  0.670081967213 for [2, 'modified_huber', (1, 2), 1000]\n",
      "f1 score:  0.668717948718 for [2, 'modified_huber', (1, 3), 1000]\n",
      "f1 score:  0.625118035883 for [2, 'modified_huber', (1, 1), 500]\n",
      "f1 score:  0.580392156863 for [3, 'modified_huber', (1, 1), 500]\n",
      "f1 score:  0.570895522388 for [2, 'modified_huber', (1, 3), 500]\n",
      "f1 score:  0.566420664207 for [2, 'modified_huber', (1, 2), 500]\n",
      "Bottom 5\n",
      "f1 score:  0.478460128323 for [2, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.476964769648 for [2, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.433544303797 for [3, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.421585160202 for [3, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.416326530612 for [3, 'modified_huber', (1, 3), 200]\n"
     ]
    }
   ],
   "source": [
    "baseball_base = printF1(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try with other classes, e.g. Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.space\n",
      "N gram = 1\n",
      "[(' space', 1087), (' orbit', 500), (' launch', 462), (' nasa', 384), (' satellit', 307), (' moon', 278), (' mission', 247), (' shuttl', 223), (' lunar', 216), (' henri', 193)]\n",
      "N gram = 2\n",
      "[(' the moon', 185), (' @ zoo.toronto.edu', 115), (' the space', 107), (' space station', 100), (' : space', 96), (' henri spencer', 94), (' nsmca @', 91), (' henri @', 90), (' prb @', 84), (' pat )', 84)]\n"
     ]
    }
   ],
   "source": [
    "getKeyWords(14,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "space_key_words = ['the moon', ' nasa', ' space station', 'satellit', 'space shuttl', 'lunar landing']\n",
    "\n",
    "#Re-run with class 14, space\n",
    "results = ModifiedGridSearch(loss_functions, n_grams, max_features_options, ratio_range, 14, space_key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "f1 score:  0.70725388601 for [2, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.684563758389 for [2, 'modified_huber', (1, 3), 1000]\n",
      "f1 score:  0.679194630872 for [2, 'modified_huber', (1, 2), 1000]\n",
      "f1 score:  0.667553191489 for [2, 'modified_huber', (1, 1), 500]\n",
      "f1 score:  0.65211062591 for [3, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.631892697466 for [3, 'modified_huber', (1, 2), 1000]\n",
      "f1 score:  0.62874251497 for [3, 'modified_huber', (1, 3), 1000]\n",
      "f1 score:  0.606488011283 for [2, 'modified_huber', (1, 2), 500]\n",
      "f1 score:  0.604255319149 for [2, 'modified_huber', (1, 3), 500]\n",
      "f1 score:  0.586552217454 for [2, 'modified_huber', (1, 1), 200]\n",
      "Bottom 5\n",
      "f1 score:  0.56346749226 for [3, 'modified_huber', (1, 2), 500]\n",
      "f1 score:  0.563218390805 for [2, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.53023255814 for [3, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.53023255814 for [3, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.524844720497 for [3, 'modified_huber', (1, 1), 200]\n"
     ]
    }
   ],
   "source": [
    "space = printF1(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now get the baseline\n",
    "results = ModifiedGridSearch(loss_functions, n_grams, max_features_options, ratio_range, 14, leave_this_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "f1 score:  0.835978835979 for [3, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.816864295125 for [2, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.802614379085 for [2, 'modified_huber', (1, 2), 1000]\n",
      "f1 score:  0.798948751643 for [2, 'modified_huber', (1, 3), 1000]\n",
      "f1 score:  0.79679144385 for [3, 'modified_huber', (1, 3), 1000]\n",
      "f1 score:  0.795727636849 for [3, 'modified_huber', (1, 2), 1000]\n",
      "f1 score:  0.757697456493 for [2, 'modified_huber', (1, 1), 500]\n",
      "f1 score:  0.752317880795 for [3, 'modified_huber', (1, 1), 500]\n",
      "f1 score:  0.748663101604 for [3, 'modified_huber', (1, 3), 500]\n",
      "f1 score:  0.745308310992 for [2, 'modified_huber', (1, 3), 500]\n",
      "Bottom 5\n",
      "f1 score:  0.63202247191 for [3, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.628853267571 for [2, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.607866507747 for [2, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.606420927467 for [2, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.597364568082 for [3, 'modified_huber', (1, 3), 200]\n"
     ]
    }
   ],
   "source": [
    "space_base = printF1(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try with middle east keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talk.politics.mideast\n",
      "N gram = 1\n",
      "[(' armenian', 1264), (' israel', 847), (' isra', 791), (' were', 734), (' turkish', 709), (' jew', 559), (' arab', 499), (' armenia', 363), (' turk', 361), (' kill', 333)]\n",
      "N gram = 2\n",
      "[(' | >', 621), (' the armenian', 486), (' , ``', 263), (' serdar argic', 245), (' the turkish', 241), (' > |', 225), (' they were', 214), (' the isra', 186), (' center for', 175), (\" . '\", 154)]\n"
     ]
    }
   ],
   "source": [
    "getKeyWords(17,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "middle_east_key_words = [' israel', ' armenian', ' turkish', ' arab', ' jew', ' armenia', ' serdar argic']\n",
    "\n",
    "results = ModifiedGridSearch(loss_functions, n_grams, max_features_options, ratio_range, 17, middle_east_key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "f1 score:  0.741239892183 for [3, 'modified_huber', (1, 1), 500]\n",
      "f1 score:  0.733590733591 for [3, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.730870712401 for [2, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.729194187583 for [2, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.725034199726 for [3, 'modified_huber', (1, 3), 500]\n",
      "f1 score:  0.723055934516 for [3, 'modified_huber', (1, 2), 500]\n",
      "f1 score:  0.715953307393 for [2, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.712328767123 for [3, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.710327455919 for [3, 'modified_huber', (1, 3), 1000]\n",
      "f1 score:  0.71 for [3, 'modified_huber', (1, 2), 1000]\n",
      "Bottom 5\n",
      "f1 score:  0.625 for [2, 'modified_huber', (1, 3), 500]\n",
      "f1 score:  0.622317596567 for [2, 'modified_huber', (1, 2), 500]\n",
      "f1 score:  0.620618556701 for [2, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.595450049456 for [2, 'modified_huber', (1, 3), 1000]\n",
      "f1 score:  0.591355599214 for [2, 'modified_huber', (1, 2), 1000]\n"
     ]
    }
   ],
   "source": [
    "middle_east = printF1(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#And re-run it with no keywords\n",
    "results = ModifiedGridSearch(loss_functions, n_grams, max_features_options, ratio_range, 17, leave_this_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "f1 score:  0.816216216216 for [2, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.795731707317 for [3, 'modified_huber', (1, 3), 1000]\n",
      "f1 score:  0.792048929664 for [3, 'modified_huber', (1, 2), 1000]\n",
      "f1 score:  0.783532536521 for [2, 'modified_huber', (1, 2), 1000]\n",
      "f1 score:  0.781914893617 for [2, 'modified_huber', (1, 3), 1000]\n",
      "f1 score:  0.781538461538 for [3, 'modified_huber', (1, 1), 1000]\n",
      "f1 score:  0.769465648855 for [3, 'modified_huber', (1, 2), 500]\n",
      "f1 score:  0.768049155146 for [3, 'modified_huber', (1, 3), 500]\n",
      "f1 score:  0.753125 for [3, 'modified_huber', (1, 1), 500]\n",
      "f1 score:  0.742637644046 for [2, 'modified_huber', (1, 3), 500]\n",
      "Bottom 5\n",
      "f1 score:  0.726094003241 for [3, 'modified_huber', (1, 2), 200]\n",
      "f1 score:  0.725806451613 for [3, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.676129032258 for [2, 'modified_huber', (1, 1), 200]\n",
      "f1 score:  0.675224646983 for [2, 'modified_huber', (1, 3), 200]\n",
      "f1 score:  0.668367346939 for [2, 'modified_huber', (1, 2), 200]\n"
     ]
    }
   ],
   "source": [
    "middle_east_base = printF1(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... its pretty clear from a range of tests that this technique does not work. In fact it produces about 10% worse accuracy, so that isn't very encouraging.\n",
    "\n",
    "Lets create a plot comparing accuracy of the method to baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA08AAAIwCAYAAABePVC6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6sHgSZIkSZJ6MHiSJEmSpB7+C7GXu6LOM/h0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9a80e177b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,9))\n",
    "\n",
    "labels = ['Baseball', 'Space', 'Middle East']\n",
    "\n",
    "plt.bar(1, baseball_base, color = 'b', label = 'Baseline')\n",
    "plt.bar(1, baseball, color = 'r', label = 'Augmented')\n",
    "\n",
    "plt.bar(2, space_base, color = 'b')\n",
    "plt.bar(2, space, color = 'r')\n",
    "\n",
    "plt.bar(3, middle_east_base, color = 'b')\n",
    "plt.bar(3, middle_east, color = 'r')\n",
    "\n",
    "plt.xticks([1,2,3], labels)\n",
    "\n",
    "title = \"Training augmentation vs. baseline classifier preformance\"\n",
    "plt.title(title, fontsize=15)\n",
    "plt.ylabel(\"F1 Scores\", fontsize=15)\n",
    "plt.xlabel(\"Class Category\", fontsize=14)\n",
    "\n",
    "plt.tick_params(labelsize=14) \n",
    "\n",
    "plt.legend(prop={'size': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next technique I will explore involves choosing a classifier with very good precision, and preferably good recall. I've printed above, the results sorted by precision, and the top one looks promising, but i'll do a more thorough search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 / 192\n",
      "50 / 192\n",
      "75 / 192\n",
      "100 / 192\n",
      "125 / 192\n",
      "150 / 192\n",
      "175 / 192\n"
     ]
    }
   ],
   "source": [
    "#Redefine the search criteria\n",
    "loss_functions = ['modified_huber','hinge'] \n",
    "n_grams = [(1,1),(1,2),(1,3)]\n",
    "max_features_options = [200, 500, 1000, None]  \n",
    "ratio_range = [2,10]  \n",
    "\n",
    "#And re-run it with notably no key words!\n",
    "results = ModifiedGridSearch(loss_functions, n_grams, max_features_options, ratio_range, 17, leave_this_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "prescision score:  1.0 for [5, 'hinge', (1, 2), None] recall:  0.582446808511\n",
      "prescision score:  1.0 for [6, 'modified_huber', (1, 2), None] recall:  0.627659574468\n",
      "prescision score:  1.0 for [6, 'hinge', (1, 2), None] recall:  0.563829787234\n",
      "prescision score:  1.0 for [6, 'hinge', (1, 3), None] recall:  0.553191489362\n",
      "prescision score:  1.0 for [7, 'hinge', (1, 2), None] recall:  0.529255319149\n",
      "prescision score:  1.0 for [7, 'hinge', (1, 3), None] recall:  0.523936170213\n",
      "prescision score:  1.0 for [8, 'modified_huber', (1, 2), None] recall:  0.577127659574\n",
      "prescision score:  1.0 for [8, 'hinge', (1, 1), None] recall:  0.542553191489\n",
      "prescision score:  1.0 for [8, 'hinge', (1, 2), 200] recall:  0.125\n",
      "prescision score:  1.0 for [8, 'hinge', (1, 2), None] recall:  0.502659574468\n"
     ]
    }
   ],
   "source": [
    "printPR(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding a balance above seems to be - prescision score:  0.989323843416 for [3, 'modified_huber', (1, 1), None] recall:  0.739361702128,  since all the precision scores are very high, and this one has the highest recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the classifier with the settings found above,\n",
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,1), max_features=None)),('tfidf', TfidfTransformer()),\n",
    "                             ('clf', SGDClassifier(loss='modified_huber', penalty='l2', alpha=1e-3,\n",
    "                               random_state=22, max_iter=5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test with class 17\n",
    "y_test = create_test_labels(17, twenty_test.target)\n",
    "X_train, y_train = create_train_set(17, 5, twenty_train_data_proc, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.82737169517884923, 0.99625468164794007, 0.70744680851063835)\n"
     ]
    }
   ],
   "source": [
    "#Confirm that it works\n",
    "print(get_metrics(text_clf, X_train, twenty_test_data_proc, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets test this on a small subset\n",
    "predict = text_clf.predict(corpus[:6000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_posts = []\n",
    "\n",
    "#Go through and see which posts were labelled 1 by the classifier\n",
    "for num in range(len(predict)):\n",
    "    if (predict[num] == 1):\n",
    "        predict_posts.append(corpus[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2456"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets see how many it found,\n",
    "len(predict_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in predict_posts:\n",
    "    X_train.append(line)\n",
    "    y_train.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8179012345679012, 0.97426470588235292, 0.70478723404255317)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "#And lastly take a look at the metrics\n",
    "get_metrics(text_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting so, the performance stays at around the same accuracy, and seems to be kind of working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will print out a few of the predicted posts to confirm this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' the un clear has a serious problem with israel .', ' they have the stronger militari , the stronger alli , more money , more resourc , and a valid reason to do just about anyth given the palestinian and their elect govern continu terror and act of war against the state of israel .', ' student and professor who use hate anti-jewish rhetor and imageri , who activ promot the dismantl of the jewish state , and who support terror against jew , do act to creat a hostil and threaten environ for mani jewish student , some of whom report at time feel physic unsaf , emot and intellectu harass and intimid by peer and professor , isol from their fellow student , and unfair treat by faculti and administr .', ' yeah that and they specif massacr jew in know jewish town that had been there centuri before .', ' you have all been post exampl of isra protest in support of palestinian .', \" dude.. you did n't get what he 's tri to say.. yes muslim countri in general seem the culprit and are the culprit.. but israel-palestin histori is way way different.. if you just look at general histori of israel-palestin , you ll find israel at fault..\", ' regard the settlement , just 26 percent of even liber jew think israel should dismantl all of them ; among moder , the figur drop to 10 percent .', ' islam is arab cultur forc onto non-arab , so of cours it is a bad thing for non-arab when muslim men ( and women ) are the vanguard of arab cultur hegemoni .', \" that 's not a turkey .\", ' child soldier are rais and forc to kill .']\n"
     ]
    }
   ],
   "source": [
    "print(predict_posts[500:510])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These actually seem fairly accuracte, I wonder what will happen if we search using this new classifier on another 600,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = text_clf.predict(corpus[6000000:12000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_posts = []\n",
    "\n",
    "#Go through and see which posts were labelled 1 by the classifier\n",
    "for num in range(len(predict)):\n",
    "    if (predict[num] == 1):\n",
    "        predict_posts.append(corpus[num+600000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "618332"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets see how many it found,\n",
    "len(predict_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in predict_posts:\n",
    "    X_train.append(line)\n",
    "    y_train.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.095105602630580502, 0.049926968530075687, 1.0)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "get_metrics(text_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm something definitly went wrong that second time, it seems the approach doesn't do very well with the train-retrain method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
